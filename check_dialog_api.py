#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Flet Dialog API –≤ –ø—Ä–æ–µ–∫—Ç–µ.

–ò—â–µ—Ç —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Dialog API:
- page.dialog = ...
- dialog.open = True
- dialog.open = False

–ò —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã:
- page.open(...)
- page.close(...)

–°–æ–∑–¥–∞—ë—Ç –æ—Ç—á—ë—Ç —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞.
"""

import re
import sys
from pathlib import Path
from dataclasses import dataclass
from typing import List, Dict, Tuple
from enum import Enum
from datetime import datetime


class FileType(Enum):
    """–¢–∏–ø —Ñ–∞–π–ª–∞."""
    TEST = "test"
    PRODUCTION = "production"
    UNKNOWN = "unknown"


class APIType(Enum):
    """–¢–∏–ø –∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–≥–æ API."""
    LEGACY = "legacy"
    MODERN = "modern"
    MIXED = "mixed"
    NONE = "none"


@dataclass
class PatternMatch:
    """–ù–∞–π–¥–µ–Ω–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω –≤ –∫–æ–¥–µ."""
    line_number: int
    column: int
    pattern_type: str  # "page.dialog", "dialog.open_true", "dialog.open_false", "page.open", "page.close"
    code_snippet: str
    context_before: str = ""
    context_after: str = ""


@dataclass
class FileAnalysisResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ —Ñ–∞–π–ª–∞."""
    file_path: str
    file_type: FileType
    api_type: APIType
    legacy_patterns: List[PatternMatch]
    modern_patterns: List[PatternMatch]
    requires_migration: bool


class DialogAPIChecker:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Dialog API –≤ —Ñ–∞–π–ª–∞—Ö."""

    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ —É—Å—Ç–∞—Ä–µ–≤—à–µ–≥–æ API
    LEGACY_PATTERNS = {
        "page.dialog": re.compile(r'page\.dialog\s*='),
        "dialog.open_true": re.compile(r'(\w+)\.open\s*=\s*True'),
        "dialog.open_false": re.compile(r'(\w+)\.open\s*=\s*False'),
    }

    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ API
    MODERN_PATTERNS = {
        "page.open": re.compile(r'page\.open\s*\('),
        "page.close": re.compile(r'page\.close\s*\('),
    }

    # –†–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    PYTHON_EXTENSIONS = {'.py'}

    # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–∏—è
    EXCLUDE_DIRS = {
        '.git', '.hypothesis', '.pytest_cache', '.ruff_cache',
        'build', 'dist', 'htmlcov', '__pycache__', '.backup',
        '.kiro', 'node_modules', '.venv', 'venv'
    }

    def __init__(self, project_root: str = "."):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ–≤–µ—Ä—è—é—â–∏–π."""
        self.project_root = Path(project_root)
        self.results: List[FileAnalysisResult] = []

    def determine_file_type(self, file_path: Path) -> FileType:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø —Ñ–∞–π–ª–∞ (—Ç–µ—Å—Ç –∏–ª–∏ production)."""
        path_str = str(file_path)
        if 'tests' in path_str or 'test_' in file_path.name:
            return FileType.TEST
        elif 'src' in path_str or 'finance_tracker' in path_str:
            return FileType.PRODUCTION
        return FileType.UNKNOWN

    def find_patterns(self, content: str, patterns: Dict[str, re.Pattern]) -> List[PatternMatch]:
        """–ù–∞—Ö–æ–¥–∏—Ç –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º —Ñ–∞–π–ª–∞."""
        matches = []
        lines = content.split('\n')

        for line_num, line in enumerate(lines, 1):
            for pattern_name, pattern_regex in patterns.items():
                for match in pattern_regex.finditer(line):
                    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç (—Å—Ç—Ä–æ–∫–∏ –¥–æ –∏ –ø–æ—Å–ª–µ)
                    context_before = lines[line_num - 2] if line_num > 1 else ""
                    context_after = lines[line_num] if line_num < len(lines) else ""

                    matches.append(PatternMatch(
                        line_number=line_num,
                        column=match.start(),
                        pattern_type=pattern_name,
                        code_snippet=line.strip(),
                        context_before=context_before.strip(),
                        context_after=context_after.strip(),
                    ))

        return matches

    def determine_api_type(self, legacy_patterns: List[PatternMatch],
                          modern_patterns: List[PatternMatch]) -> APIType:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–≥–æ API."""
        has_legacy = len(legacy_patterns) > 0
        has_modern = len(modern_patterns) > 0

        if has_legacy and has_modern:
            return APIType.MIXED
        elif has_legacy:
            return APIType.LEGACY
        elif has_modern:
            return APIType.MODERN
        else:
            return APIType.NONE

    def analyze_file(self, file_path: Path) -> FileAnalysisResult:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ–¥–∏–Ω —Ñ–∞–π–ª."""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except (UnicodeDecodeError, IOError) as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")
            return None

        file_type = self.determine_file_type(file_path)
        legacy_patterns = self.find_patterns(content, self.LEGACY_PATTERNS)
        modern_patterns = self.find_patterns(content, self.MODERN_PATTERNS)
        api_type = self.determine_api_type(legacy_patterns, modern_patterns)

        requires_migration = api_type in (APIType.LEGACY, APIType.MIXED)

        return FileAnalysisResult(
            file_path=str(file_path.relative_to(self.project_root)),
            file_type=file_type,
            api_type=api_type,
            legacy_patterns=legacy_patterns,
            modern_patterns=modern_patterns,
            requires_migration=requires_migration,
        )

    def should_skip_directory(self, dir_path: Path) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é."""
        return dir_path.name in self.EXCLUDE_DIRS

    def scan_project(self) -> List[FileAnalysisResult]:
        """–°–∫–∞–Ω–∏—Ä—É–µ—Ç –≤–µ—Å—å –ø—Ä–æ–µ–∫—Ç –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∞–π–ª—ã."""
        results = []

        for file_path in self.project_root.rglob('*.py'):
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª—ã –≤ –∏—Å–∫–ª—é—á—ë–Ω–Ω—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è—Ö
            if any(part in self.EXCLUDE_DIRS for part in file_path.parts):
                continue

            result = self.analyze_file(file_path)
            if result:
                results.append(result)

        self.results = results
        return results


class ReportGenerator:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á—ë—Ç—ã –æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –∞–Ω–∞–ª–∏–∑–∞."""

    def __init__(self, results: List[FileAnalysisResult]):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ—Ç—á—ë—Ç–æ–≤."""
        self.results = results

    def generate_summary(self) -> Dict:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–≤–æ–¥–∫—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."""
        total_files = len(self.results)
        files_with_legacy = [r for r in self.results if r.api_type in (APIType.LEGACY, APIType.MIXED)]
        files_with_modern = [r for r in self.results if r.api_type in (APIType.MODERN, APIType.MIXED)]
        test_files = [r for r in self.results if r.file_type == FileType.TEST]
        production_files = [r for r in self.results if r.file_type == FileType.PRODUCTION]

        total_legacy_patterns = sum(len(r.legacy_patterns) for r in self.results)
        total_modern_patterns = sum(len(r.modern_patterns) for r in self.results)

        return {
            'total_files': total_files,
            'files_with_legacy_api': len(files_with_legacy),
            'files_with_modern_api': len(files_with_modern),
            'test_files': len(test_files),
            'production_files': len(production_files),
            'total_legacy_patterns': total_legacy_patterns,
            'total_modern_patterns': total_modern_patterns,
            'files_requiring_migration': len([r for r in self.results if r.requires_migration]),
        }

    def print_console_report(self):
        """–í—ã–≤–æ–¥–∏—Ç –æ—Ç—á—ë—Ç –≤ –∫–æ–Ω—Å–æ–ª—å."""
        summary = self.generate_summary()

        print("\n" + "=" * 80)
        print("üìä –û–¢–ß–Å–¢ –û –ü–†–û–í–ï–†–ö–ï FLET DIALOG API")
        print("=" * 80)

        print(f"\nüìà –°–í–û–î–ö–ê:")
        print(f"  ‚Ä¢ –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: {summary['total_files']}")
        print(f"  ‚Ä¢ –§–∞–π–ª–æ–≤ —Å —É—Å—Ç–∞—Ä–µ–≤—à–∏–º API: {summary['files_with_legacy_api']}")
        print(f"  ‚Ä¢ –§–∞–π–ª–æ–≤ —Å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º API: {summary['files_with_modern_api']}")
        print(f"  ‚Ä¢ –§–∞–π–ª–æ–≤ —Ç—Ä–µ–±—É—é—â–∏—Ö –º–∏–≥—Ä–∞—Ü–∏–∏: {summary['files_requiring_migration']}")
        print(f"\n  ‚Ä¢ –¢–µ—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤: {summary['test_files']}")
        print(f"  ‚Ä¢ Production —Ñ–∞–π–ª–æ–≤: {summary['production_files']}")
        print(f"\n  ‚Ä¢ –í—Å–µ–≥–æ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {summary['total_legacy_patterns']}")
        print(f"  ‚Ä¢ –í—Å–µ–≥–æ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {summary['total_modern_patterns']}")

        # –§–∞–π–ª—ã —Ç—Ä–µ–±—É—é—â–∏–µ –º–∏–≥—Ä–∞—Ü–∏–∏
        files_to_migrate = [r for r in self.results if r.requires_migration]
        if files_to_migrate:
            print(f"\n‚ö†Ô∏è  –§–ê–ô–õ–´ –¢–†–ï–ë–£–Æ–©–ò–ï –ú–ò–ì–†–ê–¶–ò–ò ({len(files_to_migrate)}):")
            print("-" * 80)

            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø—É —Ñ–∞–π–ª–∞
            test_files = [r for r in files_to_migrate if r.file_type == FileType.TEST]
            prod_files = [r for r in files_to_migrate if r.file_type == FileType.PRODUCTION]

            if test_files:
                print(f"\n  üìù –¢–ï–°–¢–û–í–´–ï –§–ê–ô–õ–´ ({len(test_files)}):")
                for result in sorted(test_files, key=lambda r: r.file_path):
                    self._print_file_details(result)

            if prod_files:
                print(f"\n  üîß PRODUCTION –§–ê–ô–õ–´ ({len(prod_files)}):")
                for result in sorted(prod_files, key=lambda r: r.file_path):
                    self._print_file_details(result)

        # –§–∞–π–ª—ã —Å —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º API
        modern_files = [r for r in self.results if r.api_type == APIType.MODERN]
        if modern_files:
            print(f"\n‚úÖ –§–ê–ô–õ–´ –° –°–û–í–†–ï–ú–ï–ù–ù–´–ú API ({len(modern_files)}):")
            print("-" * 80)
            for result in sorted(modern_files, key=lambda r: r.file_path)[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                print(f"  ‚úì {result.file_path}")
            if len(modern_files) > 10:
                print(f"  ... –∏ –µ—â—ë {len(modern_files) - 10} —Ñ–∞–π–ª–æ–≤")

        print("\n" + "=" * 80)

    def _print_file_details(self, result: FileAnalysisResult):
        """–í—ã–≤–æ–¥–∏—Ç –¥–µ—Ç–∞–ª–∏ —Ñ–∞–π–ª–∞."""
        file_type_str = "üìù –¢–ï–°–¢" if result.file_type == FileType.TEST else "üîß PROD"
        print(f"\n  {file_type_str}: {result.file_path}")

        if result.legacy_patterns:
            print(f"    –£—Å—Ç–∞—Ä–µ–≤—à–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã ({len(result.legacy_patterns)}):")
            for pattern in result.legacy_patterns[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                print(f"      ‚Ä¢ –°—Ç—Ä–æ–∫–∞ {pattern.line_number}: {pattern.pattern_type}")
                print(f"        –ö–æ–¥: {pattern.code_snippet[:70]}")
            if len(result.legacy_patterns) > 5:
                print(f"      ... –∏ –µ—â—ë {len(result.legacy_patterns) - 5} –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤")

    def generate_json_report(self, output_file: str = "dialog_api_report.json"):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç JSON –æ—Ç—á—ë—Ç."""
        import json

        report_data = {
            'timestamp': datetime.now().isoformat(),
            'summary': self.generate_summary(),
            'files': []
        }

        for result in self.results:
            file_data = {
                'file_path': result.file_path,
                'file_type': result.file_type.value,
                'api_type': result.api_type.value,
                'requires_migration': result.requires_migration,
                'legacy_patterns': [
                    {
                        'line_number': p.line_number,
                        'pattern_type': p.pattern_type,
                        'code_snippet': p.code_snippet,
                    }
                    for p in result.legacy_patterns
                ],
                'modern_patterns': [
                    {
                        'line_number': p.line_number,
                        'pattern_type': p.pattern_type,
                        'code_snippet': p.code_snippet,
                    }
                    for p in result.modern_patterns
                ],
            }
            report_data['files'].append(file_data)

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)

        print(f"\nüíæ JSON –æ—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤: {output_file}")

    def generate_csv_report(self, output_file: str = "dialog_api_report.csv"):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç CSV –æ—Ç—á—ë—Ç."""
        import csv

        with open(output_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow([
                '–§–∞–π–ª', '–¢–∏–ø —Ñ–∞–π–ª–∞', '–¢–∏–ø API', '–¢—Ä–µ–±—É–µ—Ç –º–∏–≥—Ä–∞—Ü–∏–∏',
                '–£—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤', '–°–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤'
            ])

            for result in sorted(self.results, key=lambda r: r.file_path):
                writer.writerow([
                    result.file_path,
                    result.file_type.value,
                    result.api_type.value,
                    '–î–∞' if result.requires_migration else '–ù–µ—Ç',
                    len(result.legacy_patterns),
                    len(result.modern_patterns),
                ])

        print(f"üíæ CSV –æ—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤: {output_file}")


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    import argparse

    parser = argparse.ArgumentParser(
        description='–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Flet Dialog API –≤ –ø—Ä–æ–µ–∫—Ç–µ'
    )
    parser.add_argument(
        '--project-root',
        default='.',
        help='–ö–æ—Ä–Ω–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ø—Ä–æ–µ–∫—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: —Ç–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è)'
    )
    parser.add_argument(
        '--json',
        action='store_true',
        help='–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å JSON –æ—Ç—á—ë—Ç'
    )
    parser.add_argument(
        '--csv',
        action='store_true',
        help='–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å CSV –æ—Ç—á—ë—Ç'
    )
    parser.add_argument(
        '--output',
        default='dialog_api_report',
        help='–ë–∞–∑–æ–≤–æ–µ –∏–º—è –¥–ª—è —Ñ–∞–π–ª–æ–≤ –æ—Ç—á—ë—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: dialog_api_report)'
    )

    args = parser.parse_args()

    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É
    print("üîç –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞...")
    checker = DialogAPIChecker(args.project_root)
    results = checker.scan_project()

    print(f"‚úì –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(results)} —Ñ–∞–π–ª–æ–≤")

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á—ë—Ç—ã
    generator = ReportGenerator(results)
    generator.print_console_report()

    if args.json:
        generator.generate_json_report(f"{args.output}.json")

    if args.csv:
        generator.generate_csv_report(f"{args.output}.csv")

    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–¥ –≤—ã—Ö–æ–¥–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    files_requiring_migration = [r for r in results if r.requires_migration]
    if files_requiring_migration:
        print(f"\n‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω–æ {len(files_requiring_migration)} —Ñ–∞–π–ª–æ–≤ —Ç—Ä–µ–±—É—é—â–∏—Ö –º–∏–≥—Ä–∞—Ü–∏–∏")
        return 1
    else:
        print("\n‚úÖ –í—Å–µ —Ñ–∞–π–ª—ã –∏—Å–ø–æ–ª—å–∑—É—é—Ç —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π API!")
        return 0


if __name__ == '__main__':
    sys.exit(main())
